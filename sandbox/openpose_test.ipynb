{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "from src import model\n",
    "from src import util\n",
    "from src.body import Body\n",
    "from src.hand import Hand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Pose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_estimation = Body('model/body_pose_model.pth')\n",
    "hand_estimation = Hand('model/hand_pose_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = 'images/demo.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "detect pose and display in image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oriImg = cv2.imread(test_image)  # B,G,R order\n",
    "\n",
    "# estimate body pose and draw\n",
    "candidate, subset = body_estimation(oriImg)\n",
    "canvas = copy.deepcopy(oriImg)\n",
    "canvas = util.draw_bodypose(canvas, candidate, subset)\n",
    "\n",
    "# estimate hand pose\n",
    "hands_list = util.handDetect(candidate, subset, oriImg)\n",
    "\n",
    "all_hand_peaks = []\n",
    "for x, y, w, is_left in hands_list:\n",
    "    # cv2.rectangle(canvas, (x, y), (x+w, y+w), (0, 255, 0), 2, lineType=cv2.LINE_AA)\n",
    "    # cv2.putText(canvas, 'left' if is_left else 'right', (x, y), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "    # if is_left:\n",
    "        # plt.imshow(oriImg[y:y+w, x:x+w, :][:, :, [2, 1, 0]])\n",
    "        # plt.show()\n",
    "    peaks = hand_estimation(oriImg[y:y+w, x:x+w, :])\n",
    "    peaks[:, 0] = np.where(peaks[:, 0]==0, peaks[:, 0], peaks[:, 0]+x)\n",
    "    peaks[:, 1] = np.where(peaks[:, 1]==0, peaks[:, 1], peaks[:, 1]+y)\n",
    "    # else:\n",
    "    #     peaks = hand_estimation(cv2.flip(oriImg[y:y+w, x:x+w, :], 1))\n",
    "    #     peaks[:, 0] = np.where(peaks[:, 0]==0, peaks[:, 0], w-peaks[:, 0]-1+x)\n",
    "    #     peaks[:, 1] = np.where(peaks[:, 1]==0, peaks[:, 1], peaks[:, 1]+y)\n",
    "    #     print(peaks)\n",
    "    all_hand_peaks.append(peaks)\n",
    "\n",
    "canvas = util.draw_handpose(canvas, all_hand_peaks)\n",
    "\n",
    "plt.figure(figsize = (20,16))\n",
    "plt.imshow(canvas[:, :, [2, 1, 0]])\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect Pose in Video Frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extract frames from video:\n",
    "\n",
    "```\n",
    "mkdir pose_front\n",
    "ffmpeg -i pose_front.mov pose_front/%04d.jpg\n",
    "mkdir pose_rear\n",
    "ffmpeg -i pose_rear.mov pose_rear/%04d.jpg\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect(test_image):\n",
    "    oriImg = None\n",
    "    oriImg = cv2.imread(test_image)  # B,G,R order\n",
    "\n",
    "    # estimate body pose and draw\n",
    "    candidate, subset = body_estimation(oriImg)\n",
    "    canvas = copy.deepcopy(oriImg)\n",
    "    canvas = util.draw_bodypose(canvas, candidate, subset)\n",
    "\n",
    "    # estimate hand pose\n",
    "    hands_list = util.handDetect(candidate, subset, oriImg)\n",
    "\n",
    "    all_hand_peaks = []\n",
    "    for x, y, w, is_left in hands_list:\n",
    "        # cv2.rectangle(canvas, (x, y), (x+w, y+w), (0, 255, 0), 2, lineType=cv2.LINE_AA)\n",
    "        # cv2.putText(canvas, 'left' if is_left else 'right', (x, y), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "        # if is_left:\n",
    "            # plt.imshow(oriImg[y:y+w, x:x+w, :][:, :, [2, 1, 0]])\n",
    "            # plt.show()\n",
    "        peaks = hand_estimation(oriImg[y:y+w, x:x+w, :])\n",
    "        peaks[:, 0] = np.where(peaks[:, 0]==0, peaks[:, 0], peaks[:, 0]+x)\n",
    "        peaks[:, 1] = np.where(peaks[:, 1]==0, peaks[:, 1], peaks[:, 1]+y)\n",
    "        # else:\n",
    "        #     peaks = hand_estimation(cv2.flip(oriImg[y:y+w, x:x+w, :], 1))\n",
    "        #     peaks[:, 0] = np.where(peaks[:, 0]==0, peaks[:, 0], w-peaks[:, 0]-1+x)\n",
    "        #     peaks[:, 1] = np.where(peaks[:, 1]==0, peaks[:, 1], peaks[:, 1]+y)\n",
    "        #     print(peaks)\n",
    "        all_hand_peaks.append(peaks)\n",
    "\n",
    "    canvas = util.draw_handpose(canvas, all_hand_peaks)\n",
    "\n",
    "    # plt.figure(figsize = (20,16))\n",
    "    # plt.imshow(canvas[:, :, [2, 1, 0]])\n",
    "    # plt.axis('off')\n",
    "    # plt.show()\n",
    "\n",
    "    return canvas[:, :, [2, 1, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = detect('images/pose_front/0201.jpg')\n",
    "\n",
    "plt.figure(figsize = (20,16))\n",
    "plt.imshow(result)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(\"results/pose_front/0200.jpg\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loop over images and write to results\n",
    "\n",
    "NOTE: I had to modify the body.py code in pytorch-openpose to correct a run error. See this thread https://github.com/Hzzone/pytorch-openpose/issues/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "for frame in glob.glob(\"images/pose_front/*.jpg\"):\n",
    "    path, basename = os.path.split(frame)\n",
    "#     print(path, basename)\n",
    "    result = detect(frame)\n",
    "    outfile = os.path.join(\"results/pose_front/\", basename)\n",
    "    rgbimg = cv2.cvtColor(result, cv2.COLOR_BGR2RGB)\n",
    "    cv2.imwrite(outfile, rgbimg)\n",
    "    print(\"wrote {}...\".format(outfile))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "write frames to video with ffmpeg:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ffmpeg -framerate 30 -i results/pose_front/%04d.jpg -c:v libx264 -crf 0 output.mp4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect pose rear perspective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "for frame in glob.glob(\"images/pose_rear/*.jpg\"):\n",
    "    path, basename = os.path.split(frame)\n",
    "#     print(path, basename)\n",
    "    result = detect(frame)\n",
    "    outfile = os.path.join(\"results/pose_rear/\", basename)\n",
    "    rgbimg = cv2.cvtColor(result, cv2.COLOR_BGR2RGB)\n",
    "    cv2.imwrite(outfile, rgbimg)\n",
    "    print(\"wrote {}...\".format(outfile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write frames to file with ffmpeg\n",
    "!ffmpeg -framerate 30 -i results/pose_rear/%04d.jpg -c:v libx264 -crf 0 results/detected_pose_rear.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "another try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
